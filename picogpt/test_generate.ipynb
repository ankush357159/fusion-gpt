{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87920dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b64a0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.GPTConfig import GPTConfig\n",
    "from src.tokenizer.tokenizer import TiktokenTokenizer\n",
    "\n",
    "tokenizer = TiktokenTokenizer(encoding_name=\"gpt2\")\n",
    "config = GPTConfig(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    block_size=128,\n",
    "    embed_dim=256,\n",
    "    num_heads=8,\n",
    "    num_layers=6,\n",
    "    use_rope=False,\n",
    "    gpt2_compatible=False,\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92920738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.pico_gpt import PicoGPT\n",
    "\n",
    "model = PicoGPT(config).to(device)\n",
    "model.block_size = config.block_size\n",
    "\n",
    "checkpoint_path = \"checkpoints/picogpt_best.pt\"\n",
    "state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\"Checkpoint loaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1455dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference.generate import generate\n",
    "\n",
    "prompt = \"Once upon a time\"\n",
    "output = generate(model, tokenizer, prompt, max_new_tokens=50, device=device)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff62fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the script directly\n",
    "!python scripts/test_generate.py"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
