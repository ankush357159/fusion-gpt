{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e85eb36",
   "metadata": {},
   "source": [
    "# VeraGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d212551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set your GitHub repo URL ---\n",
    "REPO_URL = \"https://github.com/ankush357159/fusion-gpt.git\"\n",
    "REPO_DIR = \"/content/fusion-gpt\"\n",
    "\n",
    "# Clone (or re-clone) the repo\n",
    "import os\n",
    "if os.path.isdir(REPO_DIR):\n",
    "    !rm -rf \"$REPO_DIR\"\n",
    "!git clone \"$REPO_URL\" \"$REPO_DIR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a9b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install veraGPT dependencies\n",
    "%cd /content/fusion-gpt/veraGPT\n",
    "!pip -q install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b86d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) If your model is gated/private, set your HF token\n",
    "import os\n",
    "os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = \"\"  # <- paste token or leave blank for public models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3daac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a single prompt (non-interactive)\n",
    "%cd /content/fusion-gpt/veraGPT\n",
    "!python src/main.py --prompt \"Write a short welcome message for veraGPT.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c577897",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- For quantized loading, add `--quant 4` or `--quant 8` (CUDA only).\n",
    "- To load a LoRA adapter, add `--lora-path /path/to/adapter`.\n",
    "- Interactive mode is not ideal in Colab; prefer the single-prompt cell."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
